
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "Some input features can be highly correlated i.e. have a similar meaning. This adds redundancy and adds unnecessary dimensions. For example, annual income and monthly income are two different features, which essentially mean the same thing. \n",
    "\n",
    "## Solution\n",
    "Find similar input features and eliminate this redundancy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA) algorithm\n",
    "![img](https://image.slidesharecdn.com/principalcomponentanalysis-130916163816-phpapp01/95/principal-component-analysis-18-638.jpg?cb=1379350085)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I first tried to understand PCA, I found it quite daunting. <br>\n",
    "<img src=\"https://i.warosu.org/data/cgl/img/0084/62/1436443458215.png\" alt=\"img\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding PCA Graphically\n",
    "\n",
    "PCA is a technique used to reduce dimensionality. We know that while plotting data, each input feature corresponds to one dimension. Hence, graphically, PCA is the equivalent of representing high-dimension data in a low-dimension space. For example, representing a 3D Cube in a 2D space. Sounds simpler now?\n",
    "\n",
    "But how do we do this, mathematically? \n",
    "\n",
    "We use <strong>projections</strong>.\n",
    "\n",
    "Projections help us find the low-dimensional \"shadow\" of a high-dimensional object.\n",